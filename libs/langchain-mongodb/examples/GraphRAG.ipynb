{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c5b493-9b7d-45dc-be3b-9ea1c77ad7d8",
   "metadata": {},
   "source": [
    "# Knowledge Graph Construction, Querying, and Visualization\n",
    "\n",
    "This notebook demonstrates building a knowledge graph from a text corpus containing approximately 100 entities.\n",
    "\n",
    "We will:\n",
    "1. Load a large text dataset about technology companies, people, and projects\n",
    "2. Chunk the text into paragraph-sized documents using `RecursiveCharacterTextSplitter`\n",
    "3. Extract entities and relationships using `MongoDBGraphStore`\n",
    "4. Visualize the resulting knowledge graph using HoloViews and NetworkX\n",
    "\n",
    "The dataset contains news-style articles about:\n",
    "- Organizations (tech companies, research institutions, nonprofits)\n",
    "- People (CEOs, scientists, directors)\n",
    "- Projects and initiatives\n",
    "- Locations and facilities\n",
    "- Technologies and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3fb616-c1c1-4f82-b093-ad3f37a728e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import holoviews as hv\n",
    "import networkx as nx\n",
    "from holoviews import opts\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_mongodb.graphrag.graph import MongoDBGraphStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5474a3a4-fcd6-4acb-b01e-2f3afe7ff549",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc6635-87e9-4179-b6a4-404c988904c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up default plot dimensions for better viewing of large graphs\n",
    "defaults = dict(width=1200, height=800)\n",
    "hv.opts.defaults(\n",
    "    opts.EdgePaths(**defaults), opts.Graph(**defaults), opts.Nodes(**defaults)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9f1e9-48b8-42b2-83fb-3cd374c678ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = dict(width=1400, height=1000)\n",
    "hv.opts.defaults(\n",
    "    opts.EdgePaths(**defaults), opts.Graph(**defaults), opts.Nodes(**defaults)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-section",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up MongoDB connection and LLM for entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69026170-5d6d-43a1-9fbb-9a52461e1e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = os.environ.get(\"MONGODB_URI\", \"\")\n",
    "DB_NAME = \"langchain_test_db\"\n",
    "COLLECTION_NAME = \"langchain_graphrag_large_example\"\n",
    "\n",
    "# Configure the LLM for entity extraction\n",
    "# Using gpt-4o for high-quality entity extraction\n",
    "entity_extraction_model = ChatOpenAI(\n",
    "    model=\"gpt-4o\", temperature=0.0, cache=False, seed=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-section",
   "metadata": {},
   "source": [
    "## Load and Chunk Text Data\n",
    "\n",
    "Load the large text dataset and split it into paragraph-sized chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text data\n",
    "data_file = Path(\"data/articles.txt\")\n",
    "text_content = data_file.read_text()\n",
    "\n",
    "print(f\"Loaded text file with {len(text_content)} characters\")\n",
    "print(f\"Preview:\\n{text_content[:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chunk-text",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into chunks using RecursiveCharacterTextSplitter\n",
    "# This creates natural document boundaries at paragraph breaks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "text_chunks = text_splitter.split_text(text_content)\n",
    "print(f\"Split text into {len(text_chunks)} chunks\")\n",
    "\n",
    "# Convert to Document objects\n",
    "documents = [Document(page_content=chunk) for chunk in text_chunks]\n",
    "print(f\"Created {len(documents)} Document objects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graph-construction-section",
   "metadata": {},
   "source": [
    "## Build Knowledge Graph\n",
    "\n",
    "Create `MongoDBGraphStore` and extract entities from the documents.\n",
    "\n",
    "**Note:** This step takes several minutes as the LLM processes each chunk to extract entities and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-graph-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph store\n",
    "graph_store = MongoDBGraphStore(\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    database_name=DB_NAME,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    entity_extraction_model=entity_extraction_model,\n",
    "    max_depth=3,  # Allow deeper graph traversal for complex queries\n",
    ")\n",
    "\n",
    "print(f\"Created MongoDBGraphStore connected to {DB_NAME}.{COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-entities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract entities from documents\n",
    "# This may take 1-2 minutes depending on the number of chunks and LLM response time\n",
    "print(f\"Processing {len(documents)} documents...\")\n",
    "bulkwrite_results = graph_store.add_documents(documents)\n",
    "\n",
    "print(f\"Processed {len(bulkwrite_results)} document chunks\")\n",
    "print(\"Entity extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats-section",
   "metadata": {},
   "source": [
    "## Graph Statistics\n",
    "\n",
    "Examine the extracted knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graph-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count entities\n",
    "entity_count = graph_store.collection.count_documents({})\n",
    "print(f\"Total entities extracted: {entity_count}\")\n",
    "\n",
    "# Get all entities\n",
    "entities = list(graph_store.collection.find({}))\n",
    "\n",
    "# Analyze entity types\n",
    "entity_types = {}\n",
    "for entity in entities:\n",
    "    entity_type = entity.get(\"type\", \"Unknown\")\n",
    "    entity_types[entity_type] = entity_types.get(entity_type, 0) + 1\n",
    "\n",
    "print(\"\\nEntity types:\")\n",
    "for entity_type, count in sorted(\n",
    "    entity_types.items(), key=lambda x: x[1], reverse=True\n",
    "):\n",
    "    print(f\"  {entity_type}: {count}\")\n",
    "\n",
    "# Analyze relationships\n",
    "entities_with_relationships = [\n",
    "    entity for entity in entities if entity.get(\"relationships\", {}).get(\"target_ids\")\n",
    "]\n",
    "\n",
    "total_relationships = sum(\n",
    "    len(entity.get(\"relationships\", {}).get(\"target_ids\", []))\n",
    "    for entity in entities_with_relationships\n",
    ")\n",
    "\n",
    "print(\"\\nRelationships:\")\n",
    "print(f\"  Entities with relationships: {len(entities_with_relationships)}\")\n",
    "print(f\"  Total relationship edges: {total_relationships}\")\n",
    "print(\n",
    "    f\"  Average relationships per connected entity: {total_relationships / len(entities_with_relationships):.1f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-entities-section",
   "metadata": {},
   "source": [
    "## Sample Entities\n",
    "\n",
    "Display a few example entities from the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some sample entities with relationships\n",
    "print(\"Sample entities with relationships:\\n\")\n",
    "for i, entity in enumerate(entities_with_relationships[:5]):\n",
    "    print(f\"{i+1}. {entity['_id']} ({entity.get('type')})\")\n",
    "    relationships = entity.get(\"relationships\", {})\n",
    "    target_ids = relationships.get(\"target_ids\", [])\n",
    "    rel_types = relationships.get(\"types\", [])\n",
    "    print(f\"   Relationships: {len(target_ids)}\")\n",
    "    for _, (target, rel_type) in enumerate(zip(target_ids[:3], rel_types[:3])):\n",
    "        print(f\"     - {rel_type} -> {target}\")\n",
    "    if len(target_ids) > 3:\n",
    "        print(f\"     ... and {len(target_ids) - 3} more\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query-section",
   "metadata": {},
   "source": [
    "## Query the Knowledge Graph\n",
    "\n",
    "Test querying the graph to find related entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query about relationships\n",
    "query = (\n",
    "    \"What is the connection between Quantum Dynamics Corp and NanoTech Materials Ltd?\"\n",
    ")\n",
    "\n",
    "# Extract entity names from query\n",
    "entity_names = graph_store.extract_entity_names(query)\n",
    "print(f\"Extracted entities from query: {entity_names}\")\n",
    "\n",
    "# Find related entities through graph traversal\n",
    "if entity_names:\n",
    "    related_entities = graph_store.related_entities(entity_names)\n",
    "    print(f\"\\nFound {len(related_entities)} related entities:\")\n",
    "    for entity in related_entities[:10]:\n",
    "        print(f\"  - {entity['_id']} ({entity.get('type')})\")\n",
    "    if len(related_entities) > 10:\n",
    "        print(f\"  ... and {len(related_entities) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chat-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a natural language response using the knowledge graph\n",
    "answer = graph_store.chat_response(query)\n",
    "print(f\"Chat Response:\\n{answer.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-section",
   "metadata": {},
   "source": [
    "## Visualize Knowledge Graph\n",
    "\n",
    "Create interactive visualizations of the knowledge graph using HoloViews and NetworkX.\n",
    "\n",
    "### Basic Graph View\n",
    "\n",
    "First, we'll create a basic visualization of the entire graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-view",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic view of the entire graph\n",
    "basic_view = graph_store.view()\n",
    "basic_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spring-section",
   "metadata": {},
   "source": [
    "### Add view options\n",
    "\n",
    "The default view uses a force-directed layout for organic graph visualization, however we can improve on this by adding options such as a colormap for the nodes(`node_opts`, `edge_opts`) and options to the networkx layout algorithm (`nx_opts`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907f69f0-2745-4faf-a499-b85cc7f362b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_view = graph_store.view(\n",
    "    layout=nx.spring_layout,\n",
    "    nx_opts=dict(k=0.5, iterations=100),\n",
    "    edge_opts=dict(\n",
    "        edge_line_width=0.5,\n",
    "        node_color=\"type\",\n",
    "        cmap=\"Category20\",\n",
    "        node_size=10,\n",
    "    ),  #\n",
    "    node_opts=dict(size=10, color=\"type\", cmap=\"Category20\", alpha=0.8),\n",
    ")\n",
    "spring_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multipartite-section",
   "metadata": {},
   "source": [
    "### Multipartite Layout (by Entity Type)\n",
    "\n",
    "NetworkX has many different layouts available. Here we visualize the graph with entities grouped by type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88adefb-34c0-402f-84f1-24ce06a71fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multipartite layout grouping entities by type\n",
    "\n",
    "type_view = graph_store.view(\n",
    "    layout=nx.multipartite_layout,\n",
    "    nx_opts=dict(subset_key=\"type\"),\n",
    "    edge_opts=dict(\n",
    "        edge_line_width=1,\n",
    "        edge_alpha=0.5,\n",
    "        node_color=\"type\",\n",
    "        cmap=\"Category20\",\n",
    "        node_size=10,\n",
    "    ),\n",
    "    node_opts=dict(size=10, color=\"type\", cmap=\"Category20\", alpha=0.8),\n",
    ")\n",
    "type_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "networkx-section",
   "metadata": {},
   "source": [
    "### NetworkX Graph Analytics\n",
    "\n",
    "Convert to NetworkX for advanced layout algorithms and analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "to-networkx",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NetworkX graph\n",
    "nx_graph = graph_store.to_networkx()\n",
    "\n",
    "print(\n",
    "    f\"NetworkX graph: {nx_graph.number_of_nodes()} nodes, {nx_graph.number_of_edges()} edges\"\n",
    ")\n",
    "print(f\"Graph density: {nx.density(nx_graph):.4f}\")\n",
    "\n",
    "# Check if graph is connected\n",
    "if nx_graph.number_of_nodes() > 0:\n",
    "    is_connected = nx.is_connected(nx_graph.to_undirected())\n",
    "    print(f\"Is connected: {is_connected}\")\n",
    "\n",
    "    if not is_connected:\n",
    "        components = list(nx.connected_components(nx_graph.to_undirected()))\n",
    "        print(f\"Number of connected components: {len(components)}\")\n",
    "        print(f\"Largest component size: {len(max(components, key=len))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1445c6f-686b-4b80-93b5-975db986ade2",
   "metadata": {},
   "source": [
    "## Creating plots from NetworkX\n",
    "\n",
    "Though we again use HoloViews in the example below, this shows how one can compose plots without reliance on `view` alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spring-view",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spring layout (force-directed)\n",
    "spring_layout = hv.Graph.from_networkx(nx_graph, nx.spring_layout, k=0.5, iterations=50)\n",
    "\n",
    "spring_layout + spring_layout.nodes.opts(\n",
    "    size=10, color=\"type\", cmap=\"Category20\", alpha=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subgraph-section",
   "metadata": {},
   "source": [
    "### Focused Subgraph Visualization\n",
    "\n",
    "Visualize a subgraph around specific entities for detailed exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subgraph-view",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick an entity with many connections\n",
    "if entities_with_relationships:\n",
    "    # Find entity with most relationships\n",
    "    most_connected = max(\n",
    "        entities_with_relationships,\n",
    "        key=lambda e: len(e.get(\"relationships\", {}).get(\"target_ids\", [])),\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Most connected entity: {most_connected['_id']} ({most_connected.get('type')})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Number of relationships: {len(most_connected.get('relationships', {}).get('target_ids', []))}\"\n",
    "    )\n",
    "\n",
    "    # Get subgraph around this entity\n",
    "    focus_entity = most_connected[\"_id\"]\n",
    "    related = graph_store.related_entities([focus_entity], max_depth=2)\n",
    "\n",
    "    print(f\"\\nSubgraph contains {len(related)} entities\")\n",
    "\n",
    "    # Create a subgraph from these entities\n",
    "    subgraph_nodes = {entity[\"_id\"] for entity in related}\n",
    "    subgraph = nx_graph.subgraph(subgraph_nodes).copy()\n",
    "\n",
    "    print(\n",
    "        f\"Subgraph: {subgraph.number_of_nodes()} nodes, {subgraph.number_of_edges()} edges\"\n",
    "    )\n",
    "\n",
    "    # Visualize subgraph\n",
    "    if subgraph.number_of_nodes() > 0:\n",
    "        sub_spring = hv.Graph.from_networkx(\n",
    "            subgraph, nx.spring_layout, k=0.8, iterations=50\n",
    "        )\n",
    "\n",
    "        subgraph_view = sub_spring.opts(\n",
    "            inspection_policy=\"edges\",\n",
    "            node_color=\"type\",\n",
    "            cmap=\"Category20\",\n",
    "            node_size=15,\n",
    "            edge_line_width=2,\n",
    "            edge_alpha=0.6,\n",
    "            title=f\"Subgraph around {focus_entity}\",\n",
    "        ) * sub_spring.nodes.opts(\n",
    "            size=15,\n",
    "            color=\"type\",\n",
    "            cmap=\"Category20\",\n",
    "            alpha=0.9,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872485a-1de5-4a88-865f-c80678a33a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-section",
   "metadata": {},
   "source": [
    "## Export Visualizations\n",
    "\n",
    "Save the visualizations as HTML files for sharing. You can also download static images via the Bokeh widget!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger(\"bokeh.core.validation.check\").setLevel(logging.CRITICAL)\n",
    "\n",
    "# Save visualizations\n",
    "hv.save(type_view, \"graph_by_type.html\")\n",
    "print(\"Saved graph_by_type.html\")\n",
    "\n",
    "hv.save(spring_view, \"graph_spring.html\")\n",
    "print(\"Saved graph_spring.html\")\n",
    "\n",
    "print(\"\\nVisualizations exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. ✅ Loaded a large text corpus with ~100 entities\n",
    "2. ✅ Chunked text into documents using `RecursiveCharacterTextSplitter`\n",
    "3. ✅ Built a knowledge graph using `MongoDBGraphStore` and LLM-based entity extraction\n",
    "4. ✅ Analyzed graph statistics (entities, types, relationships)\n",
    "5. ✅ Queried the graph for related entities and chat responses\n",
    "6. ✅ Visualized the graph using multiple layout algorithms\n",
    "7. ✅ Explored focused subgraphs around highly-connected entities\n",
    "8. ✅ Exported interactive visualizations as HTML\n",
    "\n",
    "The resulting knowledge graph can be used for:\n",
    "- Complex multi-hop queries\n",
    "- Entity relationship discovery\n",
    "- Context-aware chat responses\n",
    "- Graph analytics and network analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
